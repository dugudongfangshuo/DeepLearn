# Generated 2021-06-05 from:
# E:\python\SER\recipe\speech_recognition\Tokenizer\tokenizer.yaml
# yamllint disable
# ############################################################################
# Tokenizer: subword BPE tokenizer with unigram 1K
# Training: Mini-LibriSpeech
# Authors:  Abdel Heba 2021
#           Mirco Ravanelli 2021
# ############################################################################


# Set up folders for reading from and writing to
data_folder: ../data
output_folder: ./save

# Path where data-specification files are stored
train_annotation: ../train.json
valid_annotation: ../valid.json
test_annotation: ../test.json

# Tokenizer parameters
token_type: unigram  # ["unigram", "bpe", "char"]
token_output: 1000  # index(blank/eos/bos/unk) = 0
character_coverage: 1.0
annotation_read: words # field to read

# Tokenizer object
tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece
  model_dir: ./save
  vocab_size: 1000
  annotation_train: ../train.json
  annotation_read: words
  model_type: unigram            # ["unigram", "bpe", "char"]
  character_coverage: 1.0
  annotation_list_to_check: [../train.json, ../valid.json]
  annotation_format: json
